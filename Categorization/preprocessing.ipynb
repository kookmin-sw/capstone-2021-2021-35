{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"preprocessing.ipynb","provenance":[{"file_id":"1EQ83uBtvfBcgtc9OQ8Ab_M6ledmWgWev","timestamp":1617903943813}],"collapsed_sections":["FnElNWZpwwcD","EZgOOBjfR5Wb","yNVVBe9eTFro","qXIjVLfQJdsk","_NBicoPJ9Mpe","xfmZOwnMPxLW","lXItOFzfFrA8","q4jblCxXSMMR"]},"kernelspec":{"display_name":"Python 3","name":"python3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"FnElNWZpwwcD"},"source":["##패키지설치"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"hCseWSL2II_p","executionInfo":{"elapsed":140175,"status":"ok","timestamp":1617800289029,"user":{"displayName":"­이하영[소프트웨어학부]","photoUrl":"","userId":"08509134292891008229"},"user_tz":-540},"outputId":"394ca974-188b-41dd-8b14-18b3c649b980"},"source":["!apt-get update \n","!apt-get install g++ openjdk-8-jdk python-dev python3-dev \n","!pip3 install JPype1-py3 \n","!pip3 install fasttext\n","!git clone https://github.com/facebookresearch/fastText\n","!cd fastText && make\n","!pip install numpy"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\r0% [Working]\r            \rGet:1 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n","\r0% [Connecting to archive.ubuntu.com (91.189.88.152)] [Connecting to security.u\r0% [Waiting for headers] [Connecting to security.ubuntu.com (91.189.91.39)] [Co\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu bionic InRelease\n","\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n","\r                                                                               \rHit:4 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n","\r0% [3 InRelease 15.6 kB/88.7 kB 18%] [Connecting to security.ubuntu.com (91.189\r0% [1 InRelease gpgv 15.9 kB] [3 InRelease 15.6 kB/88.7 kB 18%] [Connecting to \r                                                                               \rGet:5 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n","\r0% [1 InRelease gpgv 15.9 kB] [3 InRelease 30.1 kB/88.7 kB 34%] [Connecting to \r                                                                               \rGet:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n","\r0% [1 InRelease gpgv 15.9 kB] [3 InRelease 35.9 kB/88.7 kB 40%] [Connecting to \r0% [1 InRelease gpgv 15.9 kB] [3 InRelease 35.9 kB/88.7 kB 40%] [Connecting to \r0% [1 InRelease gpgv 15.9 kB] [3 InRelease 51.8 kB/88.7 kB 58%] [Waiting for he\r                                                                               \rHit:7 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n","\r0% [1 InRelease gpgv 15.9 kB] [3 InRelease 79.3 kB/88.7 kB 89%] [Waiting for he\r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Waiting for headers] [Wait\r                                                                               \rGet:8 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n","\r0% [1 InRelease gpgv 15.9 kB] [8 InRelease 20.0 kB/74.6 kB 27%] [Waiting for he\r                                                                               \r0% [1 InRelease gpgv 15.9 kB] [Waiting for headers] [Waiting for headers]\r                                                                         \rGet:9 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n","Ign:10 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n","Get:11 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,750 kB]\n","Ign:12 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n","Hit:13 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n","Hit:14 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n","Get:15 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [895 kB]\n","Get:16 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [52.7 kB]\n","Get:17 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [39.5 kB]\n","Get:18 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,476 kB]\n","Get:19 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,172 kB]\n","Get:21 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,402 kB]\n","Get:23 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,045 kB]\n","Fetched 11.1 MB in 3s (3,484 kB/s)\n","Reading package lists... Done\n","Reading package lists... Done\n","Building dependency tree       \n","Reading state information... Done\n","python-dev is already the newest version (2.7.15~rc1-1).\n","g++ is already the newest version (4:7.4.0-1ubuntu2.3).\n","g++ set to manually installed.\n","python3-dev is already the newest version (3.6.7-1~18.04).\n","python3-dev set to manually installed.\n","The following additional packages will be installed:\n","  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n","  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n","  libgtk2.0-common libxxf86dga1 openjdk-8-jdk-headless openjdk-8-jre\n","  openjdk-8-jre-headless x11-utils\n","Suggested packages:\n","  gvfs openjdk-8-demo openjdk-8-source visualvm icedtea-8-plugin libnss-mdns\n","  fonts-ipafont-gothic fonts-ipafont-mincho fonts-wqy-microhei\n","  fonts-wqy-zenhei fonts-indic mesa-utils\n","The following NEW packages will be installed:\n","  fonts-dejavu-core fonts-dejavu-extra libatk-wrapper-java\n","  libatk-wrapper-java-jni libgail-common libgail18 libgtk2.0-0 libgtk2.0-bin\n","  libgtk2.0-common libxxf86dga1 openjdk-8-jdk openjdk-8-jdk-headless\n","  openjdk-8-jre openjdk-8-jre-headless x11-utils\n","0 upgraded, 15 newly installed, 0 to remove and 59 not upgraded.\n","Need to get 43.5 MB of archives.\n","After this operation, 163 MB of additional disk space will be used.\n","Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libxxf86dga1 amd64 2:1.1.4-1 [13.7 kB]\n","Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-core all 2.37-1 [1,041 kB]\n","Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 fonts-dejavu-extra all 2.37-1 [1,953 kB]\n","Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 x11-utils amd64 7.7+3build1 [196 kB]\n","Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java all 0.33.3-20ubuntu0.1 [34.7 kB]\n","Get:6 http://archive.ubuntu.com/ubuntu bionic/main amd64 libatk-wrapper-java-jni amd64 0.33.3-20ubuntu0.1 [28.3 kB]\n","Get:7 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-common all 2.24.32-1ubuntu1 [125 kB]\n","Get:8 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-0 amd64 2.24.32-1ubuntu1 [1,769 kB]\n","Get:9 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail18 amd64 2.24.32-1ubuntu1 [14.2 kB]\n","Get:10 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgail-common amd64 2.24.32-1ubuntu1 [112 kB]\n","Get:11 http://archive.ubuntu.com/ubuntu bionic/main amd64 libgtk2.0-bin amd64 2.24.32-1ubuntu1 [7,536 B]\n","Get:12 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre-headless amd64 8u282-b08-0ubuntu1~18.04 [28.2 MB]\n","Get:13 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jre amd64 8u282-b08-0ubuntu1~18.04 [69.7 kB]\n","Get:14 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk-headless amd64 8u282-b08-0ubuntu1~18.04 [8,267 kB]\n","Get:15 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 openjdk-8-jdk amd64 8u282-b08-0ubuntu1~18.04 [1,630 kB]\n","Fetched 43.5 MB in 1s (49.7 MB/s)\n","Selecting previously unselected package libxxf86dga1:amd64.\n","(Reading database ... 160980 files and directories currently installed.)\n","Preparing to unpack .../00-libxxf86dga1_2%3a1.1.4-1_amd64.deb ...\n","Unpacking libxxf86dga1:amd64 (2:1.1.4-1) ...\n","Selecting previously unselected package fonts-dejavu-core.\n","Preparing to unpack .../01-fonts-dejavu-core_2.37-1_all.deb ...\n","Unpacking fonts-dejavu-core (2.37-1) ...\n","Selecting previously unselected package fonts-dejavu-extra.\n","Preparing to unpack .../02-fonts-dejavu-extra_2.37-1_all.deb ...\n","Unpacking fonts-dejavu-extra (2.37-1) ...\n","Selecting previously unselected package x11-utils.\n","Preparing to unpack .../03-x11-utils_7.7+3build1_amd64.deb ...\n","Unpacking x11-utils (7.7+3build1) ...\n","Selecting previously unselected package libatk-wrapper-java.\n","Preparing to unpack .../04-libatk-wrapper-java_0.33.3-20ubuntu0.1_all.deb ...\n","Unpacking libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n","Selecting previously unselected package libatk-wrapper-java-jni:amd64.\n","Preparing to unpack .../05-libatk-wrapper-java-jni_0.33.3-20ubuntu0.1_amd64.deb ...\n","Unpacking libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n","Selecting previously unselected package libgtk2.0-common.\n","Preparing to unpack .../06-libgtk2.0-common_2.24.32-1ubuntu1_all.deb ...\n","Unpacking libgtk2.0-common (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package libgtk2.0-0:amd64.\n","Preparing to unpack .../07-libgtk2.0-0_2.24.32-1ubuntu1_amd64.deb ...\n","Unpacking libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package libgail18:amd64.\n","Preparing to unpack .../08-libgail18_2.24.32-1ubuntu1_amd64.deb ...\n","Unpacking libgail18:amd64 (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package libgail-common:amd64.\n","Preparing to unpack .../09-libgail-common_2.24.32-1ubuntu1_amd64.deb ...\n","Unpacking libgail-common:amd64 (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package libgtk2.0-bin.\n","Preparing to unpack .../10-libgtk2.0-bin_2.24.32-1ubuntu1_amd64.deb ...\n","Unpacking libgtk2.0-bin (2.24.32-1ubuntu1) ...\n","Selecting previously unselected package openjdk-8-jre-headless:amd64.\n","Preparing to unpack .../11-openjdk-8-jre-headless_8u282-b08-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jre-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","Selecting previously unselected package openjdk-8-jre:amd64.\n","Preparing to unpack .../12-openjdk-8-jre_8u282-b08-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jre:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","Selecting previously unselected package openjdk-8-jdk-headless:amd64.\n","Preparing to unpack .../13-openjdk-8-jdk-headless_8u282-b08-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jdk-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","Selecting previously unselected package openjdk-8-jdk:amd64.\n","Preparing to unpack .../14-openjdk-8-jdk_8u282-b08-0ubuntu1~18.04_amd64.deb ...\n","Unpacking openjdk-8-jdk:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","Setting up libgtk2.0-common (2.24.32-1ubuntu1) ...\n","Setting up fonts-dejavu-core (2.37-1) ...\n","Setting up libxxf86dga1:amd64 (2:1.1.4-1) ...\n","Setting up fonts-dejavu-extra (2.37-1) ...\n","Setting up openjdk-8-jre-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/orbd to provide /usr/bin/orbd (orbd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/servertool to provide /usr/bin/servertool (servertool) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/tnameserv to provide /usr/bin/tnameserv (tnameserv) in auto mode\n","Setting up libgtk2.0-0:amd64 (2.24.32-1ubuntu1) ...\n","Setting up libgail18:amd64 (2.24.32-1ubuntu1) ...\n","Setting up openjdk-8-jdk-headless:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/idlj to provide /usr/bin/idlj (idlj) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsimport to provide /usr/bin/wsimport (wsimport) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jsadebugd to provide /usr/bin/jsadebugd (jsadebugd) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/native2ascii to provide /usr/bin/native2ascii (native2ascii) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/javah to provide /usr/bin/javah (javah) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/hsdb to provide /usr/bin/hsdb (hsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/clhsdb to provide /usr/bin/clhsdb (clhsdb) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/xjc to provide /usr/bin/xjc (xjc) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/schemagen to provide /usr/bin/schemagen (schemagen) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/extcheck to provide /usr/bin/extcheck (extcheck) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jhat to provide /usr/bin/jhat (jhat) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/wsgen to provide /usr/bin/wsgen (wsgen) in auto mode\n","Setting up x11-utils (7.7+3build1) ...\n","Setting up libgail-common:amd64 (2.24.32-1ubuntu1) ...\n","Setting up libatk-wrapper-java (0.33.3-20ubuntu0.1) ...\n","Setting up libgtk2.0-bin (2.24.32-1ubuntu1) ...\n","Setting up libatk-wrapper-java-jni:amd64 (0.33.3-20ubuntu0.1) ...\n","Setting up openjdk-8-jre:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/jre/bin/policytool to provide /usr/bin/policytool (policytool) in auto mode\n","Setting up openjdk-8-jdk:amd64 (8u282-b08-0ubuntu1~18.04) ...\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/appletviewer to provide /usr/bin/appletviewer (appletviewer) in auto mode\n","update-alternatives: using /usr/lib/jvm/java-8-openjdk-amd64/bin/jconsole to provide /usr/bin/jconsole (jconsole) in auto mode\n","Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n","Processing triggers for hicolor-icon-theme (0.17-2) ...\n","Processing triggers for fontconfig (2.12.6-0ubuntu2) ...\n","Processing triggers for mime-support (3.60ubuntu1) ...\n","Processing triggers for libc-bin (2.27-3ubuntu1.2) ...\n","/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n","\n","Collecting JPype1-py3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/81/63f5e4202c598f362ee4684b41890f993d6e58309c5d90703f570ab85f62/JPype1-py3-0.5.5.4.tar.gz (88kB)\n","\u001b[K     |████████████████████████████████| 92kB 6.1MB/s \n","\u001b[?25hBuilding wheels for collected packages: JPype1-py3\n","  Building wheel for JPype1-py3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for JPype1-py3: filename=JPype1_py3-0.5.5.4-cp37-cp37m-linux_x86_64.whl size=2696152 sha256=a30a515e30009d3e4ae6824eed6313afe7eaed4117c6c7a3961f6ea36506fd0e\n","  Stored in directory: /root/.cache/pip/wheels/52/37/1f/1015d908d12a0e9b239543d031fda0cded9823aa1306939541\n","Successfully built JPype1-py3\n","Installing collected packages: JPype1-py3\n","Successfully installed JPype1-py3-0.5.5.4\n","Collecting fasttext\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f8/85/e2b368ab6d3528827b147fdb814f8189acc981a4bc2f99ab894650e05c40/fasttext-0.9.2.tar.gz (68kB)\n","\u001b[K     |████████████████████████████████| 71kB 5.5MB/s \n","\u001b[?25hRequirement already satisfied: pybind11>=2.2 in /usr/local/lib/python3.7/dist-packages (from fasttext) (2.6.2)\n","Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from fasttext) (54.2.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from fasttext) (1.19.5)\n","Building wheels for collected packages: fasttext\n","  Building wheel for fasttext (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fasttext: filename=fasttext-0.9.2-cp37-cp37m-linux_x86_64.whl size=3096753 sha256=00dbf14b166496a35370e969599a593f6b8775f8e78c1df3ba5880904145d5a8\n","  Stored in directory: /root/.cache/pip/wheels/98/ba/7f/b154944a1cf5a8cee91c154b75231136cc3a3321ab0e30f592\n","Successfully built fasttext\n","Installing collected packages: fasttext\n","Successfully installed fasttext-0.9.2\n","Cloning into 'fastText'...\n","remote: Enumerating objects: 3854, done.\u001b[K\n","remote: Total 3854 (delta 0), reused 0 (delta 0), pack-reused 3854\u001b[K\n","Receiving objects: 100% (3854/3854), 8.22 MiB | 24.48 MiB/s, done.\n","Resolving deltas: 100% (2417/2417), done.\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/args.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/autotune.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/matrix.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/dictionary.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/loss.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/productquantizer.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/densematrix.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/quantmatrix.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/vector.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/model.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/utils.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/meter.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG -c src/fasttext.cc\n","c++ -pthread -std=c++11 -march=native -O3 -funroll-loops -DNDEBUG args.o autotune.o matrix.o dictionary.o loss.o productquantizer.o densematrix.o quantmatrix.o vector.o model.o utils.o meter.o fasttext.o src/main.cc -o fasttext\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.19.5)\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"7vcChZFCw3J1"},"source":["##DATASET"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TwmPbWWbl6HS","executionInfo":{"status":"ok","timestamp":1617904007518,"user_tz":-540,"elapsed":19811,"user":{"displayName":"이하영","photoUrl":"","userId":"09191202890542342793"}},"outputId":"d01cdbca-d7b7-4640-b671-1aeb1eeb9ee7"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"kgDJBgCwJK3P","executionInfo":{"status":"ok","timestamp":1617904288815,"user_tz":-540,"elapsed":895,"user":{"displayName":"이하영","photoUrl":"","userId":"09191202890542342793"}}},"source":["# car_inspect_record_info_table\n","import pandas as pd\n","import numpy as np\n","import csv\n","\n","#inspect_record_info_table\n","df = pd.read_csv('/content/drive/MyDrive/car_inspect_record_info_table.csv') \n","\n","#car_type\n","df2 = pd.read_csv('/content/drive/MyDrive/car_type.csv')\n","car_type=df2['type']\n","car_type=list(car_type)\n","# for i in range(len(car_type)) :\n","#   car_type[i]=correction(car_type[i]) #description 칼럼과 띄어쓰기및 맞춤법 동화\n","\n","#company_name\n","df2=pd.read_csv('/content/drive/MyDrive/company_name.csv')\n","company_name=df2['name']\n","company_name=list(company_name)\n","company_name+=list(df2['adminid_kor'])\n","company_name.extend([\"차케어\",\"마인디즈\",\"오토큐\",\"티스테이션\",\"태평양물산\",\"스피드메이트\",\"타이어프로\",\"원주\",\"평창\",\"애니카랜드\",\"하이카\",\"프라자\",\"T스테이션\",\"군산\",\"금호타이어\",\"기아오토큐\",\"카포유\",\"다스아우토\",\"신천열린카\",\"파인드라이브\",\"구미아주오토\",\"남양주\",\"화성\",\"고양\",\"마산\",\"제트라인모터스\",\"JJ motors\"])\n","company_name=list(set(company_name)) #중복제거\n","# # for i in range(len(company_name)) :\n","# #   company_name[i]=correction(company_name[i]) #description 칼럼과 띄어쓰기및 맞춤법 동화\n","\n","\n"],"execution_count":7,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2DVmmQ7ww-4f"},"source":["##텍스트전처리\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"EZgOOBjfR5Wb"},"source":["###특수문자제거,형태소분석,맞춤법교정\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"wK7t-BuYJRud","executionInfo":{"status":"ok","timestamp":1617904315523,"user_tz":-540,"elapsed":6737,"user":{"displayName":"이하영","photoUrl":"","userId":"09191202890542342793"}},"outputId":"747f13f6-962a-42cf-ffdd-f8cfe3de2cdc"},"source":["#특수문자제거\n","import re\n","def sub_special(s):\n","   return re.sub('[-_=+,#/\\?:;,^$.@*\\\"※~&%ㆍ!└』\\\\‘|\\(\\)\\[\\]\\<\\>`\\'…》]', ' ',s)\n","    \n","# 형태소분석\n","!pip3 install konlpy\n","from konlpy.tag import Okt\n","okt=Okt()\n","\n","def morph(s):\n","  description=''\n","  tmp = okt.pos(s, stem=True)  \n","  for token,pos in tmp: \n","    if len(token) >= 1 :\n","      if pos!='Josa' and pos!='Eomi' and pos!='KoreanParticle': \n","        description+=' '+token\n","  return description\n","\n","\n","#맞춤법, 띄어쓰기 교정 \n","!pip install git+https://github.com/ssut/py-hanspell.git # 전처리 - 띄어쓰기/ 맞춤법 검사기\n","from hanspell import spell_checker  \n","def correction(s):\n","  result = spell_checker.check(s)\n","  result.as_dict()  # dict로 출력\n","  return result[2]\n","\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: konlpy in /usr/local/lib/python3.7/dist-packages (0.5.2)\n","Requirement already satisfied: beautifulsoup4==4.6.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.6.0)\n","Requirement already satisfied: JPype1>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.2.1)\n","Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n","Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from konlpy) (0.4.4)\n","Requirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n","Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n","Requirement already satisfied: typing-extensions; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n","Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n","Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n","Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2020.12.5)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n","Requirement already satisfied: PySocks!=1.5.7,>=1.5.6; extra == \"socks\" in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n","Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.0)\n","Collecting git+https://github.com/ssut/py-hanspell.git\n","  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-29tkz_k_\n","  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-29tkz_k_\n","Requirement already satisfied (use --upgrade to upgrade): py-hanspell==1.1 from git+https://github.com/ssut/py-hanspell.git in /usr/local/lib/python3.7/dist-packages\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py-hanspell==1.1) (2.23.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n","Building wheels for collected packages: py-hanspell\n","  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for py-hanspell: filename=py_hanspell-1.1-cp37-none-any.whl size=4854 sha256=3766ed244d6944f1a8bc00fef64fca7ff12c4d749a233e7e507a33cfbf67be90\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-87f4tpy8/wheels/0a/25/d1/e5e96476dbb1c318cc26c992dd493394fe42b0c204b3e65588\n","Successfully built py-hanspell\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"yNVVBe9eTFro"},"source":["###특정데이터 클렌징"]},{"cell_type":"code","metadata":{"id":"yTL3QYW6TJtA","executionInfo":{"status":"ok","timestamp":1617904759622,"user_tz":-540,"elapsed":538,"user":{"displayName":"이하영","photoUrl":"","userId":"09191202890542342793"}}},"source":["# 특정데이터클렌징\n","def delete(s):\n","  s=re.sub(r'\\w{2,10}점',' ',s) #지점명 제거\n","  s=re.sub(r'(\\w+)역|(\\w+)출구|(\\w+)주차장(\\w+)|(\\w+)쏘카존|(\\w+)카센터|(\\w+)주민센터|(\\w+)사거리|(\\w+)테크|(\\w+)구청|(\\w+)렌트카',' ',s)\n","  s=re.sub(r'(\\w*)km','',s) #적성거리 제거 165 60 14\n","  s=re.sub(r'\\d{1,10}[원]|\\d{2,3}[,]\\d{3}[원]|\\d{2,3}[,]\\d{3}[,]\\d{3}[원]|\\d{2,3}[,]\\d{3}|\\d{2,3}[,]\\d{3}[,]\\d{3}',' ',s)  #가격 제거 \n","  s=re.sub(r'vat',' ',s) \n","  s=re.sub(r'\\d{7}|\\d{6}|\\d{2}[w][-]\\d{2,4}|\\d{2}[w]\\d{2,4}|\\d{2}[W][-]\\d{2,4}|\\d{2}[W]\\d{2,4}',' ',s) #장애번호 제거\n","  s=re.sub('장애번호|장애카드번호|장애카드',' ',s)\n","  s=re.sub(r'\\d{2,4}[00]',' ',s) #가격제거\n","  s=re.sub('\\n|\\t',' ',s)\n","  s=re.sub(r'[ㄱ,ㄴ,ㄷ,ㄹ,ㅁ,ㅇ,ㅎ]',' ',s)\n","  s=s.replace('더뉴',' ')\n","  s=s.replace('올뉴',' ')\n","  s=re.sub(r'[k,K]\\d{1}',' ',s) \n","  s=re.sub(r'[x,X][ ][D,d]|[x,X][D,d]',' ',s) \n","  s=s.replace('쏘카존','')\n","  s=s.replace('xD','')\n","  s=re.sub(r'\\d{3}[ ]\\d{2}[ ]\\d{2}|\\d{2,4}[-]\\d{1,2}[-]\\d{1,2}|\\d{1,2}[월]\\d{1,2}[일]|\\d{1,2}[월][ ]\\d{1,2}[일]',' ',s)  #날짜제거\n","  s=re.sub(r'\\d{2}[하,허,호]\\d{0,4}|\\d{4,7}',' ',s) #차량번호 제거\n","  s=re.sub(r'(\\w*)카센타|(\\w*)공업사|(\\w*)모터스',' ',s) \n","  s=re.sub(r'(\\w+)자동차|[sm,SM,Sm]d{0,2}',' ',s)\n","  s=re.sub(r'[R]\\d{1,4}[ ]\\d{1,4}[ H]\\d{1,4}',' ',s)\n","  s=re.sub(r'[R]\\d{1,4}|[RA]\\d{1,4}',' ',s)\n","  return s\n","\n","stopwords = car_type + company_name\n","stopwords.sort(reverse=True)\n","def sub_stopword(s):    #수리지점명, 차종제거\n","  for word in stopwords:\n","    s=s.replace(word,'')\n","  s=s.replace('브크','브레이크')\n","  return s\n","\n","\n","# token=[]\n","# for temp in description:\n","#   i = temp\n","#   i = str(i)\n","#   i = sub_special(i)\n","#   i = sub_stopword(i)\n","#   i = delete(i)\n","#   # i = correction(i)\n","#   # token.append(i)\n","#   # lesion.append(token)\n","#   i=morph(i)\n","#   token.append(i)\n","\n","\n","# token=list(set(token)) #중복제거\n","\n"],"execution_count":16,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"CutpzAk1bFw9"},"source":["###전처리, csv 생성"]},{"cell_type":"code","metadata":{"id":"EntzYy1hQOgZ"},"source":["description=df[['inspect_id','inspect_type','description']]\n","for i,row in description.iterrows():\n","  id=description.at[i,'inspect_id']\n","  inspect=description.at[i,'inspect_type']\n","  s=description.at[i,'description']\n","  s = str(s)\n","  s = sub_special(s)\n","  s = sub_stopword(s)\n","  s = delete(s)\n","  s = correction(s)\n","  with open('drive/MyDrive/refined_data.csv', 'a+', newline='') as f:  #CSV파일로 저장\n","    writer = csv.writer(f) \n","    writer.writerow([id,inspect,s])\n","description"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mTdTV2cBbJNH","executionInfo":{"status":"aborted","timestamp":1617904306974,"user_tz":-540,"elapsed":15310,"user":{"displayName":"이하영","photoUrl":"","userId":"09191202890542342793"}}},"source":["# df=df.dropna()\n","# description=df[['inspect_type','description']]\n","# inspect_list=list(set(df['inspect_type']))\n","# for i in inspect_list :\n","#   content=description[description['inspect_type']==i]['description']\n","#   content=list(set(content))\n","#   token=set()\n","#   for temp in content:  #클렌징\n","#     s=temp\n","#     s = str(s)\n","#     s = sub_special(s)\n","#     s = sub_stopword(s)\n","#     s = delete(s)\n","#     # s = correction(s)\n","#     token.add(s)\n","#   with open('drive/MyDrive/inspect_type.csv', 'a+', newline='') as f:  #CSV파일로 저장\n","#     writer = csv.writer(f) \n","#     writer.writerow([i,str(''.join(list(token)))])\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qXIjVLfQJdsk"},"source":["##객체명인식기"]},{"cell_type":"code","metadata":{"id":"XNPyWZbCjbuC"},"source":["# !git clone https://github.com/eagle705/pytorch-bert-crf-ner.git\n","# !pip3 install torch torchvision\n","# !pip3 install pytorch_pretrained_bert>=0.4.0\n","# !pip3 install mxnet>=1.5.0\n","# !pip3 install gluonnlp>=0.6.0\n","# !pip3 install sentencepiece>=0.1.6\n","# !pip3 install git+https://github.com/kmkurn/pytorch-crf#egg=pytorch_crf\n","# !pip3 install transformers\n","# !pip3 install tb-nightly\n","# !pip3 install future\n","# import os\n","\n","# from google.colab import drive\n","# drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"52mZdOhy9VEW"},"source":["# !python pytorch-bert-crf-ner/inference.py\n","import shutil\n","shutil.copyfile('/content/drive/MyDrive/best-epoch-12-step-1000-acc-0.960.bin', '/content/sample_data/best-epoch-12-step-1000-acc-0.960.bin')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"inWaaAwDYGN-"},"source":["!python3 pytorch-bert-crf-ner/inference.py"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"zY61MV0_2IeG","executionInfo":{"elapsed":508,"status":"ok","timestamp":1616974101014,"user":{"displayName":"­이하영[소프트웨어학부]","photoUrl":"","userId":"08509134292891008229"},"user_tz":-540},"outputId":"38f94449-7b8b-4567-89ab-8b9a54c9c850"},"source":["list_of_ner_word= [{'word': ' 왕십리역10번출구', 'tag': 'LOC', 'prob': None}, {'word': ' 유현진', 'tag': 'PER', 'prob': None}, {'word': ':239123', 'tag': 'POH', 'prob': None}, {'word': ' 창동역사거리', 'tag': 'LOC', 'prob': None}]\n","\n","# for i in list_of_ner_word:\n","#   if i['tag']=='LOC'or'PER'or'ORG'or'DAT'or'TIM'or'DUR'or'MNY'or'NOH' :\n","#     list_of_ner_word.remove(i)\n","#     print(list_of_ner_word)\n","input_text=\"왕십리역10번출구 지하주차장 김수용 유현진 비용:239123 안녕하세용\"\n","token=set()\n","for i in list_of_ner_word:\n","   if i['tag']=='LOC':\n","     token.add(i['word'])\n","token\n","\n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["{' 왕십리역10번출구', ' 창동역사거리'}"]},"metadata":{"tags":[]},"execution_count":24}]},{"cell_type":"markdown","metadata":{"id":"_NBicoPJ9Mpe"},"source":["##빈도수계산(키워드추출)"]},{"cell_type":"code","metadata":{"id":"vRMWQ3sY_Ohf"},"source":["!pip3 install krwordrank\n","from krwordrank.word import KRWordRank\n","from krwordrank.hangle import normalize"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lD0R1AELyCqi"},"source":["df = pd.read_csv('/content/drive/MyDrive/inspect_type.csv',names=['inspect_type','content'])\n","df=df.dropna()\n","for i in inspect_list:\n","  contents=df[description['inspect_type']==i]['content']\n","  contents=list(contents)\n","\n","  texts = [normalize(text, english=True, number=True) for text in contents]  # 문장내 특수문자 제거하기\n","  print(texts)\n","  wordrank_extractor = KRWordRank(\n","      min_count = 5, # 단어의 최소 출현 빈도수 (그래프 생성 시)\n","      max_length = 200, # 단어의 최대 길이\n","      verbose = True\n","      )\n","  beta = 0.85    # PageRank의 decaying factor beta\n","  max_iter = 10\n","  while(True):\n","    try:\n","      keywords, rank, graph = wordrank_extractor.extract(texts, beta, max_iter)\n","      break\n","    except:\n","      print(i)\n","\n","  for word, r in sorted(keywords.items(), key=lambda x:x[1], reverse=True)[:30]:\n","    print('%8s:\\t%.4f' % (word, r))\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hUHM0LraIuXM"},"source":[""]},{"cell_type":"markdown","metadata":{"id":"xfmZOwnMPxLW"},"source":["##라이브러리 설치, DATASET"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kdo1M_hGP8dP","executionInfo":{"elapsed":24326,"status":"ok","timestamp":1617704505637,"user":{"displayName":"­이하영[소프트웨어학부]","photoUrl":"","userId":"08509134292891008229"},"user_tz":-540},"outputId":"9df7a28c-c442-40ed-fb28-dfc6d9b37a8c"},"source":["!pip install mxnet\n","!pip install gluonnlp pandas tqdm\n","!pip install sentencepiece\n","!pip install transformers==3\n","!pip install torch\n","!pip install git+https://git@github.com/SKTBrain/KoBERT.git@master\n","import torch\n","from torch import nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import Dataset, DataLoader\n","import gluonnlp as nlp\n","import numpy as np\n","from tqdm import tqdm, tqdm_notebook\n","\n","from kobert.utils import get_tokenizer\n","from kobert.pytorch_kobert import get_pytorch_kobert_model\n","\n","from transformers import AdamW\n","from transformers.optimization import get_cosine_schedule_with_warmup\n","\n","##GPU 사용 시\n","device = torch.device(\"cuda:0\")\n","\n","bertmodel, vocab = get_pytorch_kobert_model()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: mxnet in /usr/local/lib/python3.7/dist-packages (1.8.0.post0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet) (0.8.4)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Requirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2020.12.5)\n","Requirement already satisfied: gluonnlp in /usr/local/lib/python3.7/dist-packages (0.10.0)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (1.1.5)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (4.41.1)\n","Requirement already satisfied: cython in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (0.29.22)\n","Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (1.19.5)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from gluonnlp) (20.9)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas) (2018.9)\n","Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas) (2.8.1)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->gluonnlp) (2.4.7)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas) (1.15.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (0.1.95)\n","Requirement already satisfied: transformers==3 in /usr/local/lib/python3.7/dist-packages (3.0.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2.23.0)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (4.41.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers==3) (20.9)\n","Requirement already satisfied: tokenizers==0.8.0-rc4 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.8.0rc4)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==3) (2019.12.20)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.0.44)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==3) (3.0.12)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from transformers==3) (1.19.5)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/dist-packages (from transformers==3) (0.1.95)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2020.12.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==3) (2.10)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->transformers==3) (2.4.7)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (7.1.2)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.0.1)\n","Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==3) (1.15.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (1.8.1+cu101)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch) (1.19.5)\n","Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch) (3.7.4.3)\n","Collecting git+https://****@github.com/SKTBrain/KoBERT.git@master\n","  Cloning https://****@github.com/SKTBrain/KoBERT.git (to revision master) to /tmp/pip-req-build-62f5k4wj\n","  Running command git clone -q 'https://****@github.com/SKTBrain/KoBERT.git' /tmp/pip-req-build-62f5k4wj\n","Requirement already satisfied (use --upgrade to upgrade): kobert==0.1.2 from git+https://****@github.com/SKTBrain/KoBERT.git@master in /usr/local/lib/python3.7/dist-packages\n","Building wheels for collected packages: kobert\n","  Building wheel for kobert (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for kobert: filename=kobert-0.1.2-cp37-none-any.whl size=12708 sha256=1857675db91fcbaf8be9919225679dbee91c4a58a3e3092f165837fb6747c148\n","  Stored in directory: /tmp/pip-ephem-wheel-cache-h0sylmv3/wheels/a2/b0/41/435ee4e918f91918be41529283c5ff86cd010f02e7525aecf3\n","Successfully built kobert\n","using cached model\n","using cached model\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"S3R5ELqHFksJ","executionInfo":{"elapsed":24321,"status":"ok","timestamp":1617704505640,"user":{"displayName":"­이하영[소프트웨어학부]","photoUrl":"","userId":"08509134292891008229"},"user_tz":-540},"outputId":"1f10af06-db6e-443a-9123-19c977ba3269"},"source":["print(vocab)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Vocab(size=8002, unk=\"[UNK]\", reserved=\"['[CLS]', '[SEP]', '[MASK]', '[PAD]']\")\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"SaN0hLapQ3jr","executionInfo":{"elapsed":24319,"status":"ok","timestamp":1617704505643,"user":{"displayName":"­이하영[소프트웨어학부]","photoUrl":"","userId":"08509134292891008229"},"user_tz":-540},"outputId":"a563efe3-cb06-479c-b10d-a65d49a422d8"},"source":["tokenizer = get_tokenizer()\n","tok = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["using cached model\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"lXItOFzfFrA8"},"source":["##데이터로드"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rGdTaqdHQ-hP","executionInfo":{"elapsed":22813,"status":"ok","timestamp":1617704505645,"user":{"displayName":"­이하영[소프트웨어학부]","photoUrl":"","userId":"08509134292891008229"},"user_tz":-540},"outputId":"20a6c733-19ff-4b73-cc67-f32086623827"},"source":["dataset =lesion\n","dataset"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[]"]},"metadata":{"tags":[]},"execution_count":62}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":376},"id":"FpLvSAsIPqtt","executionInfo":{"elapsed":22811,"status":"error","timestamp":1617704505647,"user":{"displayName":"­이하영[소프트웨어학부]","photoUrl":"","userId":"08509134292891008229"},"user_tz":-540},"outputId":"fdf6371a-39ff-4460-8f09-067b7c578d47"},"source":["# 가져온 내 데이터를 훈련 테스트셋과 테스트 데이터 셋으로 나누기 \n","from sklearn.model_selection import train_test_split   \n","#dataset_train, dataset_test = train_test_split(dataset, test_size=0.2, random_state=42)\n","#print(\"train shape is:\", len(dataset_train))\n","#print(\"test shape is:\", len(dataset_test))\n","# 튜토리얼에서 사용하는 데이터 로드 방식\n","# dataset_train = nlp.data.TSVDataset('/content/drive/MyDrive/Trigger_list.txt', field_indices=[1,2], num_discard_samples=1)\n","# dataset_test = nlp.data.TSVDataset(\"/content/drive/MyDrive/Trigger_list.txt\", field_indices=[1,2], num_discard_samples=1)\n","dataset_train = nlp.data.TSVDataset('/content/token.csv')\n","dataset_test = nlp.data.TSVDataset('/content/token.csv')"],"execution_count":null,"outputs":[{"output_type":"error","ename":"FileNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-63-b6c730d8a273>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# dataset_train = nlp.data.TSVDataset('/content/drive/MyDrive/Trigger_list.txt', field_indices=[1,2], num_discard_samples=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# dataset_test = nlp.data.TSVDataset(\"/content/drive/MyDrive/Trigger_list.txt\", field_indices=[1,2], num_discard_samples=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m \u001b[0mdataset_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTSVDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/token.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m \u001b[0mdataset_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTSVDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/token.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gluonnlp/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filename, encoding, sample_splitter, field_separator, num_discard_samples, field_indices, allow_missing)\u001b[0m\n\u001b[1;32m    136\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_field_indices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfield_indices\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_allow_missing\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mallow_missing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTSVDataset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_should_discard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/gluonnlp/data/dataset.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    155\u001b[0m         \u001b[0mall_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    156\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filenames\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 157\u001b[0;31m             \u001b[0;32mwith\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encoding\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    158\u001b[0m                 \u001b[0mcontent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfin\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    159\u001b[0m             \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sample_splitter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_should_discard\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/token.csv'"]}]},{"cell_type":"code","metadata":{"id":"yJWsU4TYk_VA"},"source":["print(type(dataset_train))\n","for i in range(len(dataset_train)):\n","  print(dataset_train[i])"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"q4jblCxXSMMR"},"source":["##모델학습"]},{"cell_type":"code","metadata":{"id":"oQZ3jj_IJhKq"},"source":["## Setting parameters\n","max_len = 128  # 해당 길이를 초과하는 단어에 대해선 bert가 학습하지 않음\n","batch_size = 64\n","warmup_ratio = 0.1\n","num_epochs = 180\n","max_grad_norm = 1\n","log_interval = 200\n","learning_rate =  5e-5\n","\n","class BERTDataset(Dataset):\n","    def __init__(self, dataset, sent_idx, label_idx, bert_tokenizer, max_len,\n","                 pad, pair):\n","        transform = nlp.data.BERTSentenceTransform(\n","            bert_tokenizer, max_seq_length=max_len, pad=pad, pair=pair)\n","\n","        self.sentences = [transform([i[sent_idx]]) for i in dataset]\n","        self.labels = [np.int32(i[label_idx]) for i in dataset]\n","        self.labels=0\n","\n","    def __getitem__(self, i):\n","        return (self.sentences[i] + (self.labels[i], ))\n","\n","    def __len__(self):\n","        return (len(self.labels))\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":418},"id":"yHLI4SDMSOOr","executionInfo":{"elapsed":25444,"status":"error","timestamp":1617545969689,"user":{"displayName":"­이하영[소프트웨어학부]","photoUrl":"","userId":"08509134292891008229"},"user_tz":-540},"outputId":"f1d573be-eea9-4624-c774-dbe13864ad21"},"source":["\n","data_train = BERTDataset(dataset_train, 0, 1, tok, max_len, True, False)\n","data_test = BERTDataset(dataset_test, 0, 1, tok, max_len, True, False)\n","\n","train_dataloader = torch.utils.data.DataLoader(data_train, batch_size=batch_size, num_workers=5)\n","test_dataloader = torch.utils.data.DataLoader(data_test, batch_size=batch_size, num_workers=5)\n","\n","class BERTClassifier(nn.Module):\n","    def __init__(self,\n","                 bert,\n","                 hidden_size = 768,\n","                 num_classes=151,\n","                 dr_rate=None,\n","                 params=None):\n","        super(BERTClassifier, self).__init__()\n","        self.bert = bert\n","        self.dr_rate = dr_rate\n","                 \n","        self.classifier = nn.Linear(hidden_size , num_classes)\n","        if dr_rate:\n","            self.dropout = nn.Dropout(p=dr_rate)\n","    \n","    def gen_attention_mask(self, token_ids, valid_length):\n","        attention_mask = torch.zeros_like(token_ids)\n","        for i, v in enumerate(valid_length):\n","            attention_mask[i][:v] = 1\n","        return attention_mask.float()\n","\n","    def forward(self, token_ids, valid_length, segment_ids):\n","        attention_mask = self.gen_attention_mask(token_ids, valid_length)\n","        \n","        _, pooler = self.bert(input_ids = token_ids, token_type_ids = segment_ids.long(), attention_mask = attention_mask.float().to(token_ids.device))\n","        if self.dr_rate:\n","            out = self.dropout(pooler)\n","        return self.classifier(out)\n","\n","model = BERTClassifier(bertmodel,  dr_rate=0.5).to(device)\n"," \n","# Prepare optimizer and schedule (linear warmup and decay)\n","no_decay = ['bias', 'LayerNorm.weight']\n","optimizer_grouped_parameters = [\n","    {'params': [p for n, p in model.named_parameters() if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n","    {'params': [p for n, p in model.named_parameters() if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n","]\n","\n","optimizer = AdamW(optimizer_grouped_parameters, lr=learning_rate)\n","loss_fn = nn.CrossEntropyLoss()\n","t_total = len(train_dataloader) * num_epochs\n","warmup_step = int(t_total * warmup_ratio)\n","scheduler = get_cosine_schedule_with_warmup(optimizer, num_warmup_steps=warmup_step, num_training_steps=t_total)\n","\n","\n","def calc_accuracy(X,Y):\n","    max_vals, max_indices = torch.max(X, 1)\n","    train_acc = (max_indices == Y).sum().data.cpu().numpy()/max_indices.size()[0]\n","    return train_acc\n","\n","import torch\n","torch.cuda.empty_cache()\n","\n","for e in range(num_epochs):\n","    train_acc = 0.0\n","    test_acc = 0.0\n","\n","    # train 데이터 학습\n","    model.train()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(train_dataloader)):\n","        optimizer.zero_grad()\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        loss = loss_fn(out, label)\n","        loss.backward()\n","        torch.nn.utils.clip_grad_norm_(model.parameters(), max_grad_norm)\n","        optimizer.step()\n","        scheduler.step()  # Update learning rate schedule\n","        train_acc += calc_accuracy(out, label)\n","        if batch_id % log_interval == 0:\n","            print(\"epoch {} batch id {} loss {} train acc {}\".format(e+1, batch_id+1, loss.data.cpu().numpy(), train_acc / (batch_id+1)))\n","    print(\"epoch {} train acc {}\".format(e+1, train_acc / (batch_id+1)))\n","    \n","    # test 데이터 학습\n","    model.eval()\n","    for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_dataloader)):\n","        token_ids = token_ids.long().to(device)\n","        segment_ids = segment_ids.long().to(device)\n","        valid_length= valid_length\n","        label = label.long().to(device)\n","        out = model(token_ids, valid_length, segment_ids)\n","        test_acc += calc_accuracy(out, label)\n","    print(\"epoch {} test acc {}\".format(e+1, test_acc / (batch_id+1)))\n","\n","\n","    unseen_test = pd.DataFrame([['타이어 파스', 7]], columns = [['질문 내용', '질병명']])\n","unseen_values = unseen_test.values\n","\n","test_set = BERTDataset(unseen_values, 0, 1, tok, max_len, True, False)\n","test_input = torch.utils.data.DataLoader(test_set, batch_size=1, num_workers=5)\n","\n","for batch_id, (token_ids, valid_length, segment_ids, label) in enumerate(tqdm_notebook(test_input)):\n","  token_ids = token_ids.long().to(device)\n","  segment_ids = segment_ids.long().to(device)\n","  valid_length= valid_length\n","  out = model(token_ids, valid_length, segment_ids)\n","  print(out)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:477: UserWarning: This DataLoader will create 5 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"],"name":"stderr"},{"output_type":"error","ename":"TypeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-32-e58594a2ff29>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0mloss_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# t_total = len(train_dataloader) * num_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 49\u001b[0;31m \u001b[0mt_total\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_train\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     50\u001b[0m \u001b[0mwarmup_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mt_total\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mwarmup_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0mscheduler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cosine_schedule_with_warmup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_warmup_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mwarmup_step\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_training_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mt_total\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-27-595314865cad>\u001b[0m in \u001b[0;36m__len__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mTypeError\u001b[0m: object of type 'int' has no len()"]}]}]}